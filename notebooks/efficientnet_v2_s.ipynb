{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics.classification import Accuracy\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EfficientNetV2SClassifier(pl.LightningModule):\n",
        "    def __init__(self, num_classes: int, lr: float = 1e-3):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Load the pre-trained EfficientNetV2-S model\n",
        "        weights = EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
        "        self.model = efficientnet_v2_s(weights=weights)\n",
        "\n",
        "        # Freeze the feature extractor layers\n",
        "        for param in self.model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Replace the classifier head with a new one for our specific task\n",
        "        in_features = self.model.classifier[-1].in_features\n",
        "        self.model.classifier = nn.Linear(in_features, num_classes)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
        "        return optimizer\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        self.log('train_acc', self.train_acc(logits, y), on_step=True, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = self.criterion(logits, y)\n",
        "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        self.log('val_acc', self.val_acc(logits, y), on_step=True, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None, mode=\"train\"):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "\n",
        "        self.crop_suffixes = [\n",
        "            \"_cropped_bottom_right_bright.png\",\n",
        "            \"_cropped_bottom_left_bright.png\",\n",
        "        ]\n",
        "\n",
        "        self.samples = []\n",
        "        for _, row in self.df.iterrows():\n",
        "            file_id = os.path.splitext(row[\"path\"])[0]\n",
        "            fold = row[\"fold\"]\n",
        "            label = int(row[\"class_numeric\"])\n",
        "            for suffix in self.crop_suffixes:\n",
        "                img_path = os.path.join(self.img_dir, f\"fold_{fold}\", f\"{file_id}{suffix}\")\n",
        "                if os.path.exists(img_path):\n",
        "                    self.samples.append((img_path, label))\n",
        "                else:\n",
        "                    print(f\"Image not found: {img_path}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            img = Image.new(\"RGB\", (224, 224), (0, 0, 0))\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, csv_path, image_dir, fold_val=0, batch_size=32):\n",
        "        super().__init__()\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.image_dir = image_dir\n",
        "        self.fold_val = fold_val\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_df = self.df[self.df[\"fold\"] != self.fold_val]\n",
        "        self.val_df = self.df[self.df[\"fold\"] == self.fold_val]\n",
        "        self.train_dataset = CustomImageDataset(self.train_df, self.image_dir, transform=self.transform, mode=\"train\")\n",
        "        self.val_dataset = CustomImageDataset(self.val_df, self.image_dir, transform=self.transform, mode=\"val\")\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=0)\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if __name__ == \"__main__\":\n",
        "#     csv_path = \"./data_with_folds.csv\"\n",
        "#     image_dir = \"\"\n",
        "#     fold_val = 0\n",
        "#     batch_size = 32\n",
        "#     num_classes = len(pd.read_csv(csv_path)[\"class_numeric\"].unique())\n",
        "\n",
        "#     data_module = DataModule(csv_path,\n",
        "#                             image_dir,\n",
        "#                             fold_val=fold_val,\n",
        "#                             batch_size=batch_size\n",
        "#                             )\n",
        "    \n",
        "#     model = EfficientNetV2SClassifier(num_classes=num_classes)\n",
        "\n",
        "#     trainer = pl.Trainer(\n",
        "#         max_epochs=10,\n",
        "#         accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "#         devices=\"auto\",\n",
        "#         precision=\"16-mixed\"\n",
        "#     )\n",
        "    \n",
        "#     trainer.fit(model, data_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\andre\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Users\\andre\\1JUPYTER\\Raia\\Odonto\\OsteoporosisDetection-dev\\fine_tuning\\cnn\\weights exists and is not empty.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type               | Params | Mode \n",
            "---------------------------------------------------------\n",
            "0 | model     | EfficientNet       | 20.2 M | train\n",
            "1 | criterion | CrossEntropyLoss   | 0      | train\n",
            "2 | train_acc | MulticlassAccuracy | 0      | train\n",
            "3 | val_acc   | MulticlassAccuracy | 0      | train\n",
            "---------------------------------------------------------\n",
            "3.8 K     Trainable params\n",
            "20.2 M    Non-trainable params\n",
            "20.2 M    Total params\n",
            "80.725    Total estimated model params size (MB)\n",
            "715       Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e21545214c74ff3a9322f08164b9a60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\andre\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
            "c:\\Users\\andre\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "566d0ef66a58428db88d00c57d5ec8ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2166fba2309c438690cb2a6737551f1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d221565f0b3442559c69fe95b0ee8beb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1681b740e56c4ee386c55e3d895bd7e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5555bb0af6094924a143bbb38f06a5f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d13be20e7c454a868ea91818dba6a6d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89846dfdfe194f90b53469a83b95091d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a17a8cc05b0480fa6a7658289f3d543",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d99247846d641a0b571d9843c897203",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cd85b17494d43e9b9db9ace7b840939",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29a11ca9a749444f919fbc8004e7dc67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved predictions to: classifications\\cls_efficientnetv2s.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    csv_path = \"./data_with_folds.csv\"\n",
        "    image_dir = \"\"\n",
        "    fold_val = 0\n",
        "    batch_size = 32\n",
        "    model_name = \"efficientnetv2s\"\n",
        "    weights_dir = \"weights\"\n",
        "    os.makedirs(weights_dir, exist_ok=True)\n",
        "\n",
        "    classifications_dir = \"classifications\"\n",
        "    os.makedirs(classifications_dir, exist_ok=True)\n",
        "\n",
        "    # Set number of classes from CSV\n",
        "    df = pd.read_csv(csv_path)\n",
        "    num_classes = df[\"class_numeric\"].nunique()\n",
        "\n",
        "    # Initialize data module and model\n",
        "    data_module = DataModule(csv_path, image_dir, fold_val=fold_val, batch_size=batch_size)\n",
        "    model = EfficientNetV2SClassifier(num_classes=num_classes)\n",
        "\n",
        "    # Define trainer with checkpointing\n",
        "    checkpoint_path = os.path.join(weights_dir, f\"{model_name}.ckpt\")\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=10,\n",
        "        accelerator=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        devices=\"auto\",\n",
        "        precision=\"16-mixed\",\n",
        "        default_root_dir=weights_dir,\n",
        "        callbacks=[pl.callbacks.ModelCheckpoint(\n",
        "            dirpath=weights_dir,\n",
        "            filename=model_name,\n",
        "            save_top_k=1,\n",
        "            monitor=\"val_acc\",\n",
        "            mode=\"max\"\n",
        "        )]\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.fit(model, data_module)\n",
        "\n",
        "    # Load best model for prediction\n",
        "    best_model = EfficientNetV2SClassifier.load_from_checkpoint(checkpoint_path, num_classes=num_classes)\n",
        "    best_model.eval()\n",
        "    best_model.freeze()\n",
        "\n",
        "    # Inference on full dataset\n",
        "    full_dataset = CustomImageDataset(df, image_dir, transform=data_module.transform, mode=\"val\")\n",
        "    full_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    predictions = []\n",
        "    paths = []\n",
        "    for imgs, _ in full_loader:\n",
        "        with torch.no_grad():\n",
        "            preds = best_model(imgs.to(best_model.device))\n",
        "            cls = preds.argmax(dim=1).cpu().tolist()\n",
        "            predictions.extend(cls)\n",
        "\n",
        "    # Construct prediction mapping\n",
        "    flat_paths = [sample[0] for sample in full_dataset.samples]\n",
        "    file_names = [os.path.basename(p).split('_')[0] + '.png' for p in flat_paths]\n",
        "\n",
        "    # Add predictions to original df\n",
        "    pred_df = pd.DataFrame({\n",
        "        'path': file_names,\n",
        "        f'cls_{model_name}': predictions\n",
        "    })\n",
        "\n",
        "    # Remove duplicates in case of augmentations\n",
        "    pred_df = pred_df.groupby('path').agg(lambda x: x.mode()[0]).reset_index()\n",
        "\n",
        "    merged_df = df.merge(pred_df, on=\"path\", how=\"left\")\n",
        "    output_csv_path = os.path.join(classifications_dir, f\"cls_{model_name}.csv\")\n",
        "    merged_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "    print(f\"Saved predictions to: {output_csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            " [[94 15  3]\n",
            " [33 48  2]\n",
            " [ 9 22  5]]\n",
            "Precision (weighted): 0.6159409218232748\n",
            "Recall (weighted): 0.6363636363636364\n",
            "Accuracy: 0.6363636363636364\n",
            "F1 Score (weighted): 0.6067440874092849\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\n",
        "\n",
        "# Load the CSV\n",
        "df = pd.read_csv(\"C:/Users/andre/1JUPYTER/Raia/Odonto/OsteoporosisDetection-dev/fine_tuning/cnn/classifications/cls_efficientnetv2.csv\")\n",
        "\n",
        "# Filter for fold == 0\n",
        "df_fold_0 = df[df[\"fold\"] == 0]\n",
        "\n",
        "# Extract true and predicted labels\n",
        "y_true = df_fold_0[\"class_numeric\"]\n",
        "y_pred = df_fold_0[\"cls_efficientnetv2s\"]\n",
        "\n",
        "# Compute metrics\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Precision (weighted):\", precision)\n",
        "print(\"Recall (weighted):\", recall)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score (weighted):\", f1_score(y_true, y_pred, average='weighted', zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
